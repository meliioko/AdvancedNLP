{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "kUD-eP5Y3uNZ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "db70c077f2184bd3b3f7435f107563aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a5b1c9c78cca450eb5d85670e9110d02",
              "IPY_MODEL_71caa7a94c454634ba8661b69c46add1",
              "IPY_MODEL_e5e3e14f8e40468ba95ae25ce100e260"
            ],
            "layout": "IPY_MODEL_254ca72aaa414745bde346220a866e43"
          }
        },
        "a5b1c9c78cca450eb5d85670e9110d02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7095d0c556e4467b9e8e5604331de9f1",
            "placeholder": "​",
            "style": "IPY_MODEL_983eba5dd1c4492b8f8c28ed5d553a5e",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "71caa7a94c454634ba8661b69c46add1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b80167bb9533417e9d52b0a575642ae8",
            "max": 516,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b6ea27bc30c4198bd4ee8308c1b887c",
            "value": 516
          }
        },
        "e5e3e14f8e40468ba95ae25ce100e260": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5eaf6b540ebe4405adcf0f8df951ed9c",
            "placeholder": "​",
            "style": "IPY_MODEL_690ca8ede6934fe4b21d20b4419e2bb1",
            "value": " 516/516 [00:00&lt;00:00, 8.99kB/s]"
          }
        },
        "254ca72aaa414745bde346220a866e43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7095d0c556e4467b9e8e5604331de9f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "983eba5dd1c4492b8f8c28ed5d553a5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b80167bb9533417e9d52b0a575642ae8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b6ea27bc30c4198bd4ee8308c1b887c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5eaf6b540ebe4405adcf0f8df951ed9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "690ca8ede6934fe4b21d20b4419e2bb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e05f0bf923c47d6a918472abd537d68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e1ff6f10ed234ce58ff36bce592eb340",
              "IPY_MODEL_4eba60fc37484c42938ca5d82586dd9f",
              "IPY_MODEL_336253e69adf4310a56f29fa0aba18b7"
            ],
            "layout": "IPY_MODEL_e9d1f74066ee4fe78d3f13cb910020c6"
          }
        },
        "e1ff6f10ed234ce58ff36bce592eb340": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b2bfd03b31c40a285f620da1723fda9",
            "placeholder": "​",
            "style": "IPY_MODEL_84d307655dfd4f6e88cb7643dd183864",
            "value": "tokenizer.json: 100%"
          }
        },
        "4eba60fc37484c42938ca5d82586dd9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c6c8e58de91490787ee01c2f89dc5b4",
            "max": 2420898,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2d2a43559a5d42d0862106ae15001954",
            "value": 2420898
          }
        },
        "336253e69adf4310a56f29fa0aba18b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d503f405d3774354b082752fa2ad4451",
            "placeholder": "​",
            "style": "IPY_MODEL_7c23b336975f432bad5c71c628478199",
            "value": " 2.42M/2.42M [00:00&lt;00:00, 9.81MB/s]"
          }
        },
        "e9d1f74066ee4fe78d3f13cb910020c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b2bfd03b31c40a285f620da1723fda9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84d307655dfd4f6e88cb7643dd183864": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c6c8e58de91490787ee01c2f89dc5b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d2a43559a5d42d0862106ae15001954": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d503f405d3774354b082752fa2ad4451": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c23b336975f432bad5c71c628478199": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c97234a2f8d42f4950386571809e893": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11d2e07925d1434fabf12c90aca69aae",
              "IPY_MODEL_9f3f7d1869504019b7b18c5e82fb31e0",
              "IPY_MODEL_73e42b6396274eb2a1ab3f9e165c48f9"
            ],
            "layout": "IPY_MODEL_de576bce15cc4555988d1b723069d516"
          }
        },
        "11d2e07925d1434fabf12c90aca69aae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bbabaf97ec743398276f1860d8547a9",
            "placeholder": "​",
            "style": "IPY_MODEL_2d8b001d51324c398136cc3ad0216d2e",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "9f3f7d1869504019b7b18c5e82fb31e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f15bd9447e214323898cda29cb1fe2c6",
            "max": 354,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ce2a1224ea0b43b1923c70a5957aa06a",
            "value": 354
          }
        },
        "73e42b6396274eb2a1ab3f9e165c48f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbff5d5d4e9649029e8b50a61e107c97",
            "placeholder": "​",
            "style": "IPY_MODEL_4c332f3137d04dbba6ff595d5de9af52",
            "value": " 354/354 [00:00&lt;00:00, 4.96kB/s]"
          }
        },
        "de576bce15cc4555988d1b723069d516": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bbabaf97ec743398276f1860d8547a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d8b001d51324c398136cc3ad0216d2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f15bd9447e214323898cda29cb1fe2c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce2a1224ea0b43b1923c70a5957aa06a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dbff5d5d4e9649029e8b50a61e107c97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c332f3137d04dbba6ff595d5de9af52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Translation & Multilingual NLP\n",
        "\n",
        "## Goal of the session\n",
        "\n",
        "**Part I - Machine Translation**: you are going to train a small encoder-decoder from scratch on English-French data. Use backtranslation and iterative backtranslation to improve your results.\n",
        "\n",
        "**Part II - Multilingual NLP**: you are going to compare CamemBERT & RoberTA on XLNI French. Finetune your previous MT models on in-domain data (similarly to what was presented in the slides) to improve RoberTA results.\n",
        "\n",
        "❗❗❗ SELECT A GPU HARDWARE ❗❗❗"
      ],
      "metadata": {
        "id": "aP8foRD32ILW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part I - Machine Translation"
      ],
      "metadata": {
        "id": "kUD-eP5Y3uNZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Requirements\n",
        "\n",
        "Install packages & download data"
      ],
      "metadata": {
        "id": "XrsFWWr64OwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers evaluate datasets"
      ],
      "metadata": {
        "id": "3BaluGqv2LcN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc613814-dc2a-4a9a-f58e-1e14460c75db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m751.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Collecting dill (from evaluate)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n",
            "Collecting multiprocess (from evaluate)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Collecting responses<0.19 (from evaluate)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
            "Installing collected packages: dill, responses, multiprocess, datasets, evaluate\n",
            "Successfully installed datasets-2.16.1 dill-0.3.7 evaluate-0.4.1 multiprocess-0.70.15 responses-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWIxK1Ul2Hp-"
      },
      "outputs": [],
      "source": [
        "!npm install -g github-files-fetcher\n",
        "!fetcher --url=https://github.com/multi30k/dataset/tree/master/data/task1/raw"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gunzip raw/*\n",
        "!rm raw/*de raw/*cs"
      ],
      "metadata": {
        "id": "5WrydAuY6G3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo raw/*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2fiVNv5AxS6",
        "outputId": "017f5b10-333a-4156-be6a-29a60cc1d7ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "raw/test_2016_flickr.en raw/test_2016_flickr.fr raw/test_2017_flickr.en raw/test_2017_flickr.fr raw/test_2017_mscoco.en raw/test_2017_mscoco.fr raw/test_2018_flickr.en raw/test_2018_flickr.fr raw/train.en raw/train.fr raw/val.en raw/val.fr\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train a Transformer encoder-decoder on Multi30k English => French.\n",
        "\n",
        "**Config**: 4 layers - 4 heads - hidden_dim 128 - feedforward_dim 256"
      ],
      "metadata": {
        "id": "SeC0FM0e8hOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "from typing import Optional"
      ],
      "metadata": {
        "id": "YndfvGgf8hj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## TODO: Write a dataset class. Use test_2016_flickr as test set\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "  def __init__(self, split: str):\n",
        "    super(MyDataset, self).__init__()\n",
        "\n",
        "    self.datapath = \"./raw/\"\n",
        "    self.tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
        "    ## To complete\n",
        "\n",
        "  def __len__(self):\n",
        "    ## To complete: size must be < 4000\n",
        "    ...\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    ## To complete: Must return a dict of torch.Tensor with two keys 'src' and 'tgt'\n",
        "    ...\n"
      ],
      "metadata": {
        "id": "Wk1Rwq1I9c_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## TODO: Write a collate_fn to pad your batch - Have a look at section 2 pad_sequence here: https://suzyahyah.github.io/pytorch/2019/07/01/DataLoader-Pad-Pack-Sequence.html\n",
        "\n",
        "def collate_fn(batch):\n",
        "  ## To complete: Must return a batch dict of padded torch.Tensor with two keys 'src' and 'tgt'\n",
        "  ..."
      ],
      "metadata": {
        "id": "ZAIjHDp3_zjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = MyDataset(split=\"train\")\n",
        "dev_data = MyDataset(split=\"val\")\n",
        "test_data = MyDataset(split=\"test\")\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=16, shuffle=True, num_workers=2, collate_fn=collate_fn)\n",
        "dev_loader = DataLoader(dev_data, batch_size=16, shuffle=False, num_workers=2, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_data, batch_size=16, shuffle=False, num_workers=2, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "ppDe7HwAArsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## TODO: Model definition with the following config: 4 layers - 4 heads - hidden_dim 128 - feedforward_dim 256\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "  def __init__(self):\n",
        "\n",
        "    self.positional_encodings = nn.PositionalEncoding(...)\n",
        "    self.embeddings = nn.Embedding(...) # To complete (have a look at the number of tokens in the tokenizer)\n",
        "    self.transformer = nn.Transformer(...) # To complete\n",
        "\n",
        "  def forward(self, x: torch.Tensor, y: Optional[torch.Tensor] = None):\n",
        "    # To complete: Don't forget to build masks! See here for more details: https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html\n",
        "    ...\n",
        "\n",
        "model = MyModel()\n",
        "print(f\"Transformer with {sum([p.numel() for p in model.parameters()])} parameters\")  # Print num params"
      ],
      "metadata": {
        "id": "ZV11rf0uK53x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## TODO: Build optimizer and training loop\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "optimizer = optim.Adam(...) # To complete\n",
        "loss_fn = nn.CrossEntropyLoss(...)  # To complete: don't forget to ignore the padding index!\n",
        "\n",
        "NUM_EPOCH = 5\n",
        "\n",
        "for epoch in range(NUM_EPOCH):\n",
        "  print(f\"Epoch {epoch}\")\n",
        "\n",
        "  # Train\n",
        "  model.train()\n",
        "  train_loss, dev_loss = [], []\n",
        "  for batch_idx, batch in enumerate(train_loader, 1):\n",
        "\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "    # Forward pass: To complete\n",
        "    ...\n",
        "\n",
        "    # Backward pass: To complete\n",
        "    ...\n",
        "\n",
        "    # Don't forget to add the loss to train_loss\n",
        "    if not batch_idx % 10:\n",
        "      print(f\"Epoch {epoch} - Batch idx {batch_idx} - Train loss {np.mean(train_loss)}\")\n",
        "\n",
        "  # Val\n",
        "  model.eval()\n",
        "  for batch in val_loader:\n",
        "\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "    # Eval pass: To complete\n",
        "    with torch.no_grad():\n",
        "      ...\n",
        "\n",
        "    # Don't forget to add the loss to dev_loss\n",
        "\n",
        "  print(f\"Epoch {epoch} - Dev set - Loss {np.mean(dev_loss)}\")\n"
      ],
      "metadata": {
        "id": "Yuf-cUdSOHoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## TODO: Find best hyperparameters on dev set for decoding (top-k, temperature)\n",
        "## Vary top-k and temperature to decode sentences\n",
        "## Have a look at https://huggingface.co/spaces/evaluate-metric/bleu for using BLEU score\n",
        "## Don't forget to detokenize output sequence before feeding it to BLEU\n",
        "\n",
        "import evaluate\n",
        "bleu = evaluate.load(\"bleu\")\n",
        "\n",
        "output_logits = {t: [] for t in [0.1, 1.0, 10.0]}  # Different temperature values\n",
        "for batch in val_loader:\n",
        "\n",
        "  batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    logits = model(...).detach().cpu() # To complete\n",
        "\n",
        "    for t in output_logits.keys():\n",
        "      probs = ... # To complete: turn logits into probabilities with temperature t\n",
        "      output_logits[t].append(probs)\n",
        "\n",
        "\n",
        "# Load references from MyDataset\n",
        "references = [...]  # To complete\n",
        "\n",
        "# Test different top-k values\n",
        "topk_bleu_scores = {k: {t: \"\" for t in output_logits.keys()} for k in [1, 5, 10]}\n",
        "for k in [1, 5, 10]:\n",
        "  for t in output_logits.keys():\n",
        "\n",
        "    translations = []\n",
        "    # Sample with top-k value\n",
        "    for probs in output_logits[t]:\n",
        "\n",
        "      decoded_translation = ... # To complete: decode translation\n",
        "      translations.append(decoded_translation)\n",
        "\n",
        "    # Compute BLEU score\n",
        "    bleu_score = ... # To complete\n",
        "    topk_bleu_scores[k][t] = bleu_score"
      ],
      "metadata": {
        "id": "hBK8rbg_RPVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## TODO: Compute BLEU on test set using the selected hyperparameters"
      ],
      "metadata": {
        "id": "i4skKmXFWpIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BackTranslation: Train a Transformer encoder-decoder on Multi30k French => English. Add test_2017_flickr and test_2018_flickr as the backtranslated data (using previous model)\n",
        "\n",
        "**Config**: 4 layers - 4 heads - hidden_dim 128 - feedforward_dim 256"
      ],
      "metadata": {
        "id": "kn4GIJpWQ67E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## TODO: use previous model to create synthetic Fr => En parallel data\n",
        "additional_training_data = MyDataset(...)  # To complete to load test_2017 and test_2018 French data - Modify MyDataset class if necessary\n",
        "additional_loader = DataLoader(additional_training_data, batch_size=16, num_workers=2, collate_fn=collate_fn)\n",
        "tokenizer = additional_training_data.tokenizer\n",
        "\n",
        "fr_data, en_data = [], []\n",
        "for batch in additional_loader:\n",
        "\n",
        "  batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "  en_data += [...]  # To complete: decode src sentences with tokenizer\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    logits = model(...).detach().cpu() # To complete\n",
        "\n",
        "    probs = ... # To complete: turn logits into probabilities with temperature t chosen in previous cells\n",
        "\n",
        "    # Sample with top-k chosen in previous cells - To complete\n",
        "    for prob in probs:\n",
        "      translation = ...\n",
        "      fr_data.append(...)"
      ],
      "metadata": {
        "id": "lCpcpbrBXzmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## TODO: train a model for Fr => En and evaluate (similar to previous block)"
      ],
      "metadata": {
        "id": "r1AajEJ7uVpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Iterative BackTranslation:\n",
        "\n",
        "- Iterative Backtranslation consists of training two models src <=> tgt simultaneously. While the first one trains, the second one is frozen and provides backtranslated data. At the end of the epoch, the first one becomes frozen and provides the backtranslated data while the second one trains.\n",
        "\n",
        "\n",
        "Train simultaneously two Transformer encoder-decoder on Multi30k French => English & English => French. Add test_2017_flickr and test_2018_flickr as the backtranslated data\n",
        "\n",
        "**Config**: 4 layers - 4 heads - hidden_dim 128 - feedforward_dim 256"
      ],
      "metadata": {
        "id": "ghLiGtMIutkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel(...)  # To complete\n",
        "reverse_model = MyModel(...)  # To complete\n",
        "\n",
        "# First iteration - no backtranslated data\n",
        "## TODO: Build optimizer and training loop\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "reverse_model.to(device)\n",
        "\n",
        "optimizer = optim.Adam(...) # To complete\n",
        "rev_optimizer = optim.Adam(...) # To complete\n",
        "loss_fn = nn.CrossEntropyLoss(...)  # To complete: don't forget to ignore the padding index!\n",
        "\n",
        "# Train\n",
        "model.train()\n",
        "reverse_model.to(device)\n",
        "train_loss, dev_loss, rev_train_loss, rev_dev_loss = [], []\n",
        "for batch_idx, batch in enumerate(train_loader, 1):\n",
        "\n",
        "  batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "  # Forward pass: To complete\n",
        "  ...\n",
        "\n",
        "  # Backward pass: To complete\n",
        "  ...\n",
        "\n",
        "  # Don't forget to add the loss to train_loss\n",
        "  if not batch_idx % 10:\n",
        "    print(f\"Epoch {epoch} - Batch idx {batch_idx} - En => Fr Train loss {np.mean(train_loss)}\")\n",
        "    print(f\"Epoch {epoch} - Batch idx {batch_idx} - Fr => En Train loss {np.mean(rev_train_loss)}\")\n",
        "\n",
        "# Val\n",
        "model.eval()\n",
        "reverse_model.eval()\n",
        "for batch in val_loader:\n",
        "\n",
        "  batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "  # Eval pass: To complete\n",
        "  with torch.no_grad():\n",
        "    ...\n",
        "\n",
        "  # Don't forget to add the loss to dev_loss\n",
        "\n",
        "print(f\"Epoch {epoch} - Dev set - En => Fr Loss {np.mean(dev_loss)}\")\n",
        "print(f\"Epoch {epoch} - Dev set - Fr => En Loss {np.mean(rev_dev_loss)}\")\n"
      ],
      "metadata": {
        "id": "GEm5bz6Ov1Pd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## TODO: Iterate\n",
        "NUM_ITERATIONS = 5\n",
        "\n",
        "for _iter in range(NUM_ITERATIONS):\n",
        "  ...  # To complete, don't forget to freeze one model when training the other"
      ],
      "metadata": {
        "id": "cmV3rc7mw5i-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## TODO: Eval on test_2016 & compare the three methods, which one gives the best BLEU score?"
      ],
      "metadata": {
        "id": "7nVjK6fCxY6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part II: Multilingual NLP"
      ],
      "metadata": {
        "id": "XjzZIWHcW4CM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Requirements\n",
        "\n",
        "Install packages"
      ],
      "metadata": {
        "id": "kuki-oC_4dWy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[sentencepiece] evaluate datasets sentencepiece accelerate peft sacremoses\n",
        "!pip install -U sentence-transformers"
      ],
      "metadata": {
        "id": "CgjmXwpE4hqU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c32f7de5-c20d-4efd-cef6-6b43460cfe81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=a3b11dacafac00f082f8363066b3d346542d9f73458f30134bf34fc5b94f44e7\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentence-transformers\n",
            "Successfully installed sentence-transformers-2.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoModelForSequenceClassification, AutoTokenizer\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix\n",
        "import accelerate\n",
        "import peft\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "k35GfzZ0W9T3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download translation models & classification models & their tokenizers"
      ],
      "metadata": {
        "id": "zEHMW9RHJjvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "translation_model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-fr-en\")\n",
        "back_translation_model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-en-fr\")\n",
        "fren_tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-fr-en\")\n",
        "enfr_tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-fr\")\n",
        "\n",
        "translation_model.to(device)\n",
        "back_translation_model.to(device)"
      ],
      "metadata": {
        "id": "_ysSx6Ir3WtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "camembert_nli = AutoModelForSequenceClassification.from_pretrained(\"mtheo/camembert-base-xnli\")\n",
        "camembert_tokenizer = AutoTokenizer.from_pretrained(\"mtheo/camembert-base-xnli\")\n",
        "\n",
        "camembert_nli.to(device)"
      ],
      "metadata": {
        "id": "WYroPKsJGm1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 899,
          "referenced_widgets": [
            "db70c077f2184bd3b3f7435f107563aa",
            "a5b1c9c78cca450eb5d85670e9110d02",
            "71caa7a94c454634ba8661b69c46add1",
            "e5e3e14f8e40468ba95ae25ce100e260",
            "254ca72aaa414745bde346220a866e43",
            "7095d0c556e4467b9e8e5604331de9f1",
            "983eba5dd1c4492b8f8c28ed5d553a5e",
            "b80167bb9533417e9d52b0a575642ae8",
            "1b6ea27bc30c4198bd4ee8308c1b887c",
            "5eaf6b540ebe4405adcf0f8df951ed9c",
            "690ca8ede6934fe4b21d20b4419e2bb1",
            "6e05f0bf923c47d6a918472abd537d68",
            "e1ff6f10ed234ce58ff36bce592eb340",
            "4eba60fc37484c42938ca5d82586dd9f",
            "336253e69adf4310a56f29fa0aba18b7",
            "e9d1f74066ee4fe78d3f13cb910020c6",
            "2b2bfd03b31c40a285f620da1723fda9",
            "84d307655dfd4f6e88cb7643dd183864",
            "1c6c8e58de91490787ee01c2f89dc5b4",
            "2d2a43559a5d42d0862106ae15001954",
            "d503f405d3774354b082752fa2ad4451",
            "7c23b336975f432bad5c71c628478199",
            "9c97234a2f8d42f4950386571809e893",
            "11d2e07925d1434fabf12c90aca69aae",
            "9f3f7d1869504019b7b18c5e82fb31e0",
            "73e42b6396274eb2a1ab3f9e165c48f9",
            "de576bce15cc4555988d1b723069d516",
            "1bbabaf97ec743398276f1860d8547a9",
            "2d8b001d51324c398136cc3ad0216d2e",
            "f15bd9447e214323898cda29cb1fe2c6",
            "ce2a1224ea0b43b1923c70a5957aa06a",
            "dbff5d5d4e9649029e8b50a61e107c97",
            "4c332f3137d04dbba6ff595d5de9af52"
          ]
        },
        "outputId": "c7637dea-82ea-40c1-e9b3-447d89b5e737"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/516 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db70c077f2184bd3b3f7435f107563aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e05f0bf923c47d6a918472abd537d68"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/354 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9c97234a2f8d42f4950386571809e893"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CamembertForSequenceClassification(\n",
              "  (roberta): CamembertModel(\n",
              "    (embeddings): CamembertEmbeddings(\n",
              "      (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): CamembertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x CamembertLayer(\n",
              "          (attention): CamembertAttention(\n",
              "            (self): CamembertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): CamembertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): CamembertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): CamembertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): CamembertClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import CrossEncoder\n",
        "roberta_nli = CrossEncoder('cross-encoder/nli-roberta-base')\n",
        "roberta_nli.model.to(device)"
      ],
      "metadata": {
        "id": "JtzmCA2ZHhC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of parameters of the translation model: {sum([p.numel() for p in translation_model.parameters()])}\")\n",
        "print(f\"Number of parameters of CamemBERT: {sum([p.numel() for p in camembert_nli.parameters()])}\")\n",
        "print(f\"Number of parameters of RoBERTa: {sum([p.numel() for p in roberta_nli.model.parameters()])}\")"
      ],
      "metadata": {
        "id": "ABalJugHG2K3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7487bec8-9fc3-47f9-e000-7666ea3c6bbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters of the translation model: 75133952\n",
            "Number of parameters of CamemBERT: 110624259\n",
            "Number of parameters of RoBERTa: 124647939\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load data"
      ],
      "metadata": {
        "id": "ue0VneCEJ5tz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_fr = load_dataset(\"xnli\", data_files=\"fr/test-00000-of-00001.parquet\")[\"train\"]\n",
        "test_data_en = load_dataset(\"xnli\", data_files=\"en/test-00000-of-00001.parquet\")[\"train\"]\n",
        "data_en = load_dataset(\"xnli\", data_files=\"en/train-00000-of-00001.parquet\")[\"train\"]\n",
        "data_fr = load_dataset(\"xnli\", data_files=\"fr/train-00000-of-00001.parquet\")[\"train\"]"
      ],
      "metadata": {
        "id": "0uBiWdlgETAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "_BATCH_SIZE = 128\n",
        "\n",
        "test_loader_fr = DataLoader(test_data_fr, batch_size=_BATCH_SIZE, num_workers=2)"
      ],
      "metadata": {
        "id": "L_wWCo-NRJO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Translate test_data_fr into English using translation_model\n",
        "\n",
        "Use top-p sampling with p=0.8"
      ],
      "metadata": {
        "id": "6kE3cOGVLGTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_en_translated_from_fr = {\"premise\": [], \"hypothesis\": [], \"label\": []}\n",
        "\n",
        "pad_token_id = fren_tokenizer.pad_token_id\n",
        "translation_model.eval()\n",
        "for sample in tqdm(test_loader_fr):\n",
        "\n",
        "  premise_inps = fren_tokenizer(sample[\"premise\"], return_tensors=\"pt\", padding=True)\n",
        "  hypothesis_inps = fren_tokenizer(sample[\"hypothesis\"], return_tensors=\"pt\", padding=True)\n",
        "\n",
        "  # Transfer to current device\n",
        "  premise_inps = {k: v.to(device) for k, v in premise_inps.items()}\n",
        "  hypothesis_inps = {k: v.to(device) for k, v in hypothesis_inps.items()}\n",
        "\n",
        "  with torch.no_grad():\n",
        "    # Compute translations\n",
        "    tr_premise_ids = translation_model.generate(**premise_inps, num_beams=1,\n",
        "                                            do_sample=True, top_p=0.8,\n",
        "                                            top_k=0, temperature=0.6,\n",
        "                                            pad_token_id=pad_token_id)\n",
        "    tr_hyp_ids = translation_model.generate(**hypothesis_inps, num_beams=1,\n",
        "                                        do_sample=True, top_p=0.8,\n",
        "                                        top_k=0, temperature=0.6,\n",
        "                                        pad_token_id=pad_token_id)\n",
        "\n",
        "    ## Detokenize\n",
        "    test_data_en_translated_from_fr[\"premise\"] += fren_tokenizer.batch_decode(tr_premise_ids, skip_special_tokens=True)\n",
        "    test_data_en_translated_from_fr[\"hypothesis\"] += fren_tokenizer.batch_decode(tr_hyp_ids, skip_special_tokens=True)\n",
        "    test_data_en_translated_from_fr[\"label\"] += sample[\"label\"]\n"
      ],
      "metadata": {
        "id": "_eAbD4kvLFqh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c6ef711-79e2-4dc5-9c6a-98b59754d481"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [01:31<00:00,  2.28s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute score of RoBERTa (translate-test baseline)"
      ],
      "metadata": {
        "id": "gi1t3EMIU8e7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "inputs = [(premise, hypothesis) for premise, hypothesis in zip(test_data_en_translated_from_fr[\"premise\"],\n",
        "                                                               test_data_en_translated_from_fr[\"hypothesis\"])]\n",
        "\n",
        "t0 = time.time()\n",
        "logits = roberta_nli.predict(inputs)\n",
        "print(f\"Time to compute logits: {time.time() - t0}\")\n",
        "\n",
        "#label_mapping = ['contradiction', 'entailment', 'neutral']\n",
        "labels_matching = {1: 0, 2: 1, 0: 2}\n",
        "preds = logits.argmax(axis=1)\n",
        "preds = np.array([labels_matching[lab] for lab in preds])\n",
        "gt = np.array(test_data_en_translated_from_fr[\"label\"])"
      ],
      "metadata": {
        "id": "SsI8tLyPHstQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7332159-2d16-4a4f-9a2f-ba807d089c9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time to compute logits: 18.42674446105957\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Compute scores\n",
        "accuracy = accuracy_score(gt, preds)\n",
        "_f1_score = f1_score(gt, preds, average=\"weighted\")\n",
        "recall = recall_score(gt, preds, average=\"weighted\")\n",
        "precision = precision_score(gt, preds, average=\"weighted\")\n",
        "\n",
        "print(f\"Translate test - Accuracy: {accuracy:.3f}\")\n",
        "print(f\"Translate test - F1 Score: {_f1_score:.3f}\")\n",
        "print(f\"Translate test - Recall: {recall:.3f}\")\n",
        "print(f\"Translate test - Precision: {precision:.3f}\")\n",
        "\n",
        "print(confusion_matrix(gt, preds))"
      ],
      "metadata": {
        "id": "_2MfGptUJQ3T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86581659-cf36-4527-8ca1-f00d893b10a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translate test - Accuracy: 0.808\n",
            "Translate test - F1 Score: 0.807\n",
            "Translate test - Recall: 0.808\n",
            "Translate test - Precision: 0.822\n",
            "[[1143  389  138]\n",
            " [  80 1442  148]\n",
            " [  29  178 1463]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute score of CamemBERT"
      ],
      "metadata": {
        "id": "XzQ2UZkabQsm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "-PFtTMeaGBsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## TODO: Compute XNLI score on test_data_fr.\n",
        "## Have a look here: https://huggingface.co/docs/transformers/model_doc/camembert#transformers.CamembertForSequenceClassification\n",
        "## Tokenizer usage:\n",
        "##    camembert_tokenizer(premise, hypothesis, return_tensors='pt', padding=True)"
      ],
      "metadata": {
        "id": "oH3hcLaybThi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tune translation model using the method from Artexte et al. (2023) described in class. We will focus on the domain adaptation method in the MT adaptation section.\n",
        "\n",
        "To recap:\n",
        "Back translate English training data into French and use the parallel data to fine-tune the translation model using LORA.\n",
        "\n",
        "Recompute translations once done and recompute scores of translate-test baseline (RoBERTa)."
      ],
      "metadata": {
        "id": "uTTTFB-kbXFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_trainable_parameters(model):\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.2f}\"\n",
        "    )"
      ],
      "metadata": {
        "id": "isKAKqoSMOTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_trainable_parameters(translation_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pq3Qu0KMPXh",
        "outputId": "e6aa7791-b4ad-4a25-8094-8bed2012a1d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 74609664 || all params: 75133952 || trainable%: 99.30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        ")\n",
        "lora_translation_model = get_peft_model(translation_model, config)\n",
        "print_trainable_parameters(lora_translation_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bN5Vum3MeAL",
        "outputId": "82808a36-8947-4b74-b2d0-5d02bc20a2bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 589824 || all params: 75723776 || trainable%: 0.78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Back Translate English training data into French using backtranslate language model"
      ],
      "metadata": {
        "id": "4ikWOUFotEyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### TODO: Back translation - reuse code from previous blocks\n",
        "\n",
        "_BATCH_SIZE = 128\n",
        "\n",
        "train_loader_en = DataLoader(data_en, batch_size=_BATCH_SIZE // 2, num_workers=2, shuffle=False)\n",
        "training_data_fr_translated_from_en = {\"premise\": [], \"hypothesis\": [], \"label\": []}\n",
        "\n",
        "pad_token_id = enfr_tokenizer.pad_token_id\n",
        "back_translation_model.eval()\n",
        "for batch_idx, sample in tqdm(enumerate(train_loader_en, 1)):\n",
        "\n",
        "  if batch_idx == 250:\n",
        "    break\n",
        "\n",
        "  premise_inps = enfr_tokenizer(sample[\"premise\"], return_tensors=\"pt\", padding=True)\n",
        "  hypothesis_inps = enfr_tokenizer(sample[\"hypothesis\"], return_tensors=\"pt\", padding=True)\n",
        "\n",
        "  # Transfer to current device\n",
        "  premise_inps = {k: v.to(device) for k, v in premise_inps.items()}\n",
        "  hypothesis_inps = {k: v.to(device) for k, v in hypothesis_inps.items()}\n",
        "\n",
        "  with torch.no_grad():\n",
        "    # Compute translations\n",
        "    tr_premise_ids = back_translation_model.generate(**premise_inps, num_beams=1,\n",
        "                                            do_sample=True, top_p=0.8,\n",
        "                                            top_k=0, temperature=0.6,\n",
        "                                            pad_token_id=pad_token_id)\n",
        "    tr_hyp_ids = back_translation_model.generate(**hypothesis_inps, num_beams=1,\n",
        "                                        do_sample=True, top_p=0.8,\n",
        "                                        top_k=0, temperature=0.6,\n",
        "                                        pad_token_id=pad_token_id)\n",
        "\n",
        "    ## Detokenize\n",
        "    training_data_fr_translated_from_en[\"premise\"] += enfr_tokenizer.batch_decode(tr_premise_ids, skip_special_tokens=True)\n",
        "    training_data_fr_translated_from_en[\"hypothesis\"] += enfr_tokenizer.batch_decode(tr_hyp_ids, skip_special_tokens=True)\n",
        "    training_data_fr_translated_from_en[\"label\"] += sample[\"label\"]\n"
      ],
      "metadata": {
        "id": "-A0O9zTitBeu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60f67ab7-bb9a-409f-f055-33a3ae2e70a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "249it [08:57,  2.16s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use the back-translated data to fine-tune translation_model (fr => en)"
      ],
      "metadata": {
        "id": "16aQh4f3uBzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### TODO: finetune translation_model on the back translated data. Reuse code from Partie I (training loop)"
      ],
      "metadata": {
        "id": "wNd8uaBSuKY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Recompute results translate test for the domain adapted translation_model"
      ],
      "metadata": {
        "id": "qIEZrxRnuUJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### TODO: Recompute results - reuse code from previous blocks"
      ],
      "metadata": {
        "id": "yYEP5Xi3uZhP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}