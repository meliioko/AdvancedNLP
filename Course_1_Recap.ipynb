{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Course 1 : Recap\n",
        "\n",
        "The slides of the course are available [here](https://github.com/NathanGodey/AdvancedNLP/raw/main/slides/pdf/course2_tokenization.pdf)\n",
        "\n",
        "## Goal of the session\n",
        "\n",
        "We are going to build a system that identify emotions in an English social media post.\n",
        "\n",
        "❗❗❗ SELECT A GPU HARDWARE ❗❗❗"
      ],
      "metadata": {
        "id": "AtmR96U_oimo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 0: Install libraries\n",
        "\n",
        "Let's install the following HuggingFace's libraries:\n",
        "- `transformers`: a module that allows downloading and using NLP models (among others)\n",
        "- `datasets`: a module that handles dataset downloading and management"
      ],
      "metadata": {
        "id": "uLHkQaz3ooZ2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-fLdDucoOci"
      },
      "outputs": [],
      "source": [
        "!pip install datasets transformers > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# write your imports here"
      ],
      "metadata": {
        "id": "4emJWUjAq5OD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Get a Language Model\n",
        "\n",
        "In this session, we are going to use a pre-trained language model. Let's first download one, and observe how good it is at its pretraining task (Masked Language Modeling."
      ],
      "metadata": {
        "id": "arDLLad_q8W1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 1\n",
        "Using `transformers`'s `AutoModelForMaskedLM`, load the `distilbert-base-cased` language model [available here](https://huggingface.co/distilbert-base-cased). Print it to see what layers it contains."
      ],
      "metadata": {
        "id": "0z7__OJ4r2Dp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3siW1DQlwdmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 2\n",
        "\n",
        "Using `transformers`'s `AutoTokenizer`, load the tokenizer for  `distilbert-base-cased` [available here](https://huggingface.co/distilbert-base-cased). How many tokens does it have in its vocabulary? Use it to tokenize this sentence:"
      ],
      "metadata": {
        "id": "cRTPrSqJsmOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_sentence = \"This model seems to work preeeetty well.\""
      ],
      "metadata": {
        "id": "8fqW3p_us6cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can actually use the `return_tensors=\"pt\"` argument in the tokenizer to get a Torch tensor."
      ],
      "metadata": {
        "id": "o2bGW44Avnf-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 3\n"
      ],
      "metadata": {
        "id": "E2mAF2F5smLX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the tokenized sentence (as a Torch tensor) through the model."
      ],
      "metadata": {
        "id": "Qx4qXEV1sdPj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qPpK1i4Pv2Zh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "That took quite some time... Can we do faster?"
      ],
      "metadata": {
        "id": "MCFLH4J-v21d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 4\n",
        "Load all tensors and the model onto the GPU using the `.cuda()` method. Run the tokenized sentence through the model. Was it faster?"
      ],
      "metadata": {
        "id": "Adv2vyytv-Mf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Phxi1P6TwcKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the shape of `logits`? What do you think it represents?"
      ],
      "metadata": {
        "id": "f2elkoeHw0Uj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 5\n",
        "What is DistilBERT's favorite ice-cream flavor?"
      ],
      "metadata": {
        "id": "dHRp6lrMwe6j"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "daabekrAwlza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Get a dataset\n",
        "We are going to download a dataset of Reddit posts annotated for emotion recognition."
      ],
      "metadata": {
        "id": "m0B6kxtgxM8k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 6\n",
        "Download [this dataset](https://huggingface.co/datasets/go_emotions) using the `load_dataset` function of the `datasets` module. Select the \"raw\" config. What is the returned object made of?"
      ],
      "metadata": {
        "id": "-nog1cOfyiiW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BRt_JqBjzCVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 7\n",
        "How many emotions are labeled? Can there be several labels at the same time? What is the frequency of each label?"
      ],
      "metadata": {
        "id": "O2rPdU-tzBx8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pJeePf1x0lbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 8\n",
        "Using a regular expression (regex), find out what percentage of user profiles end with a number (e.g. User456)."
      ],
      "metadata": {
        "id": "P-FXyrXE0luB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z8u_hMmU1O0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 9\n",
        "Using a regular expression (regex), find out what percentage of messages use smileys (e.g. \":)\" or \":/\")"
      ],
      "metadata": {
        "id": "Mh-F3OxF1MDI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eNCGjiNy2DH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Fine-tuning"
      ],
      "metadata": {
        "id": "nN4DA0gM2DWr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 10\n",
        "We first need to prepare the model for fine-tuning. What should be the shape and range of the predictions of the fine-tuned model? With that in mind, build a prediction head and use it to replace the current LM head.\n",
        "\n",
        "**Tip**: You will need `torch.nn.Linear` and an [activation function](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity). You also need to pick a pooling strategy to get only one vector for each sequence."
      ],
      "metadata": {
        "id": "wO3tMFyv2jla"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DZ7bUeCe3344"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 11\n",
        "Build a `collate_fn` for the fine-tuning. It should:\n",
        "- Take a batch of rows from the dataset as an input\n",
        "- Tokenize the `text` as a `torch.Tensor`\n",
        "- Retrieve the labels associated with the emotions and turn them into a `torch.Tensor`\n",
        "- Return the tokenized text and the labels in a dictionary"
      ],
      "metadata": {
        "id": "yARBODa234FO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_emotions(rows):\n",
        "  ..."
      ],
      "metadata": {
        "id": "ia0ink4g4tLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 12\n",
        "Split the dataset in two parts : `train`:90%, `val`:10%. You can use the [dedicated method](https://huggingface.co/docs/datasets/v2.14.5/en/package_reference/main_classes#datasets.Dataset.train_test_split). Create a dataloader for each split using the `collate_emotions` function."
      ],
      "metadata": {
        "id": "6xrt4B4W5b1g"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Amik6wO64t2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_batch = next(iter(train_dataloader))"
      ],
      "metadata": {
        "id": "hiXlDvkL6sBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 13\n",
        "\n"
      ],
      "metadata": {
        "id": "8nsLl88C6iOc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the `test_batch` variable, make a prediction using the untrained model from Question 10. How can we compare the model's output with the expected labels? What loss is best suited for this problem?"
      ],
      "metadata": {
        "id": "-3gH6iXj6xzh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OeREMu0B6riA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 14\n",
        "\n",
        "In order to fine-tune the model, we are going to use the [Pytorch-Lightning module](https://lightning.ai/docs/pytorch/stable/). Fill out the missing parts:"
      ],
      "metadata": {
        "id": "FZAJw-Dx7HES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightning"
      ],
      "metadata": {
        "id": "pumWEiA07K22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lightning.pytorch as pl\n",
        "\n",
        "# define the LightningModule\n",
        "class FineTuner(pl.LightningModule):\n",
        "  def __init__(self, model, learning_rate, weight_decay):\n",
        "    super().__init__()\n",
        "    self.model = model\n",
        "    self.learning_rate = learning_rate\n",
        "    self.weight_decay = weight_decay\n",
        "\n",
        "  def common_step(self, batch, batch_idx):\n",
        "    # You may need to adapt this :\n",
        "    input_ids, labels = batch[\"input_ids\"], batch[\"labels\"]\n",
        "\n",
        "    # TO COMPLETE\n",
        "\n",
        "    return loss, predictions, labels\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    loss, _, _ = self.common_step(batch, batch_idx)\n",
        "    self.log(\"train_loss\", loss)\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    loss, predictions, labels = self.common_step(batch, batch_idx)\n",
        "\n",
        "    accuracy = ...  # to complete\n",
        "\n",
        "    self.log(\"val_loss\", loss)\n",
        "    self.log(\"val_accuracy\", accuracy)\n",
        "\n",
        "    return loss\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    optimizer = ...\n",
        "    lr_scheduler = ...\n",
        "\n",
        "    return [optimizer], [lr_scheduler]"
      ],
      "metadata": {
        "id": "h1TlWnvv7fOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pl_module = FineTuner(\n",
        "    model=...,\n",
        "    learning_rate=...,\n",
        "    weight_decay=...,\n",
        ")\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    accumulate_grad_batches=1,\n",
        "    gradient_clip_val=None,\n",
        "    max_epochs=3,\n",
        "    precision=32,\n",
        "    val_check_interval=1.,\n",
        ")"
      ],
      "metadata": {
        "id": "SVc5JufRYxaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 15\n",
        "Write a function that asks an input from the user and outputs the labels corresponding to the emotions in the written sentence."
      ],
      "metadata": {
        "id": "AAKddTWWjYCz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8qIHBGKsjsoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 16\n",
        "\n",
        "Re-initialize the DistilBERT model using the `init_weights` method. Fine-tune it with the previous approach. What can you say about the final performance?"
      ],
      "metadata": {
        "id": "xcMaHDkaO4Ht"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m-bR_2lyPIVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 17\n",
        "\n",
        "Create a class using a `torch.nn.LSTM` model that behaves like the `BertModel` class from `HuggingFace`. Fine-tune it with the previous approach. What can you say about the final performance?"
      ],
      "metadata": {
        "id": "xhrrx8gCOSgE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TF3TKy-fO5BQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}